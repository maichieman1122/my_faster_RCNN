{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0dd164c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import  absolute_import\n",
    "import os\n",
    "from collections import namedtuple\n",
    "import time\n",
    "from torch.nn import functional as F\n",
    "from model.utils.creator_tool import AnchorTargetCreator, ProposalTargetCreator\n",
    "from torch import nn\n",
    "import torch as t\n",
    "from our_utils import array_tool as at\n",
    "from our_utils.vis_tool import Visualizer\n",
    "\n",
    "from our_utils.config import opt\n",
    "from torchnet.meter import ConfusionMeter, AverageValueMeter\n",
    "\n",
    "LossTuple = namedtuple('LossTuple',\n",
    "                       ['rpn_loc_loss',\n",
    "                        'rpn_cls_loss',\n",
    "                        'roi_loc_loss',\n",
    "                        'roi_cls_loss',\n",
    "                        'total_loss'\n",
    "                        ])\n",
    "\n",
    "class FasterRCNNTrainer(nn.Module):\n",
    "    def __init__(self, faster_rcnn):\n",
    "        super(FasterRCNNTrainer, self).__init__()\n",
    "        self.faster_rcnn=faster_rcnn\n",
    "        self.rpn_sigma=opt.rpn_sigma\n",
    "        self.roi_sigma=opt.roi_sigma\n",
    "        \n",
    "        self.anchor_target_creator = AnchorTargetCreator()\n",
    "        self.proposal_target_creator = ProposalTargetCreator()\n",
    "        \n",
    "        self.loc_normalize_mean = faster_rcnn.loc_normalize_mean\n",
    "        self.loc_normalize_std = faster_rcnn.loc_normalize_std\n",
    "        \n",
    "        self.optimizer = self.faster_rcnn.get_optimizer()\n",
    "        self.vis = Visualizer(env=opt.env)\n",
    "        \n",
    "        self.rpn_cm = ConfusionMeter(2)\n",
    "        self.roi_cm = ConfusionMeter(21)\n",
    "        self.meters = {k: AverageValueMeter() for k in LossTuple._fields}  # average loss\n",
    "        \n",
    "    def forward(self, imgs, bboxes, labels, scale):\n",
    "        n = bboxes.shape[0]\n",
    "        if n != 1:\n",
    "            raise ValueError('Currently only batch size 1 is supported.')\n",
    "        _,_,H,W=imgs.shape\n",
    "        img_size=(H,W)\n",
    "        features=self.faster_rcnn.extractor(imgs)\n",
    "        rpn_locs, rpn_scores, rois, roi_indices, anchor = \\\n",
    "            self.faster_rcnn.rpn(features, img_size, scale)\n",
    "        \n",
    "        bbox=bboxes[0]\n",
    "        label=labels[0]\n",
    "        rpn_score = rpn_scores[0]\n",
    "        rpn_loc = rpn_locs[0]\n",
    "        roi = rois\n",
    "        sample_roi, gt_roi_loc, gt_roi_label = self.proposal_target_creator(\n",
    "            roi,\n",
    "            at.tonumpy(bbox),\n",
    "            at.tonumpy(label),\n",
    "            self.loc_normalize_mean,\n",
    "            self.loc_normalize_std)\n",
    "        \n",
    "        sample_roi_index = t.zeros(len(sample_roi))\n",
    "        roi_cls_loc, roi_score = self.faster_rcnn.head(\n",
    "            features,\n",
    "            sample_roi,\n",
    "            sample_roi_index)\n",
    "        \n",
    "        # ------------------ RPN losses -------------------#\n",
    "        gt_rpn_loc, gt_rpn_label = self.anchor_target_creator(\n",
    "            at.tonumpy(bbox),\n",
    "            anchor,\n",
    "            img_size)\n",
    "        gt_rpn_label = at.totensor(gt_rpn_label).long()\n",
    "        gt_rpn_loc = at.totensor(gt_rpn_loc)\n",
    "        rpn_loc_loss = _fast_rcnn_loc_loss(\n",
    "            rpn_loc,\n",
    "            gt_rpn_loc,\n",
    "            gt_rpn_label.data,\n",
    "            self.rpn_sigma)\n",
    "\n",
    "        # NOTE: default value of ignore_index is -100 ...\n",
    "        rpn_cls_loss = F.cross_entropy(rpn_score, gt_rpn_label.cuda(), ignore_index=-1)\n",
    "        _gt_rpn_label = gt_rpn_label[gt_rpn_label > -1]\n",
    "        _rpn_score = at.tonumpy(rpn_score)[at.tonumpy(gt_rpn_label) > -1]\n",
    "        self.rpn_cm.add(at.totensor(_rpn_score, False), _gt_rpn_label.data.long())\n",
    "\n",
    "        # ------------------ ROI losses (fast rcnn loss) -------------------#\n",
    "        n_sample = roi_cls_loc.shape[0]\n",
    "        roi_cls_loc = roi_cls_loc.view(n_sample, -1, 4)\n",
    "        roi_loc = roi_cls_loc[t.arange(0, n_sample).long().cuda(), \\\n",
    "                              at.totensor(gt_roi_label).long()]\n",
    "        gt_roi_label = at.totensor(gt_roi_label).long()\n",
    "        gt_roi_loc = at.totensor(gt_roi_loc)\n",
    "\n",
    "        roi_loc_loss = _fast_rcnn_loc_loss(\n",
    "            roi_loc.contiguous(),\n",
    "            gt_roi_loc,\n",
    "            gt_roi_label.data,\n",
    "            self.roi_sigma)\n",
    "\n",
    "        roi_cls_loss = nn.CrossEntropyLoss()(roi_score, gt_roi_label.cuda())\n",
    "\n",
    "        self.roi_cm.add(at.totensor(roi_score, False), gt_roi_label.data.long())\n",
    "\n",
    "        losses = [rpn_loc_loss, rpn_cls_loss, roi_loc_loss, roi_cls_loss]\n",
    "        losses = losses + [sum(losses)]\n",
    "\n",
    "        return LossTuple(*losses)\n",
    "    \n",
    "    def train_step(self, imgs, bboxes, labels, scale):\n",
    "        self.optimizer.zero_grad()\n",
    "        losses = self.forward(imgs, bboxes, labels, scale)\n",
    "        losses.total_loss.backward()\n",
    "        self.optimizer.step()\n",
    "        self.update_meters(losses)\n",
    "        return losses\n",
    "    \n",
    "    \n",
    "    def save(self, save_optimizer=False, save_path=None, **kwargs):\n",
    "        \"\"\"serialize models include optimizer and other info\n",
    "        return path where the model-file is stored.\n",
    "        Args:\n",
    "            save_optimizer (bool): whether save optimizer.state_dict().\n",
    "            save_path (string): where to save model, if it's None, save_path\n",
    "                is generate using time str and info from kwargs.\n",
    "        \n",
    "        Returns:\n",
    "            save_path(str): the path to save models.\n",
    "        \"\"\"\n",
    "        save_dict = dict()\n",
    "\n",
    "        save_dict['model'] = self.faster_rcnn.state_dict()\n",
    "        save_dict['config'] = opt._state_dict()\n",
    "        save_dict['other_info'] = kwargs\n",
    "        save_dict['vis_info'] = self.vis.state_dict()\n",
    "\n",
    "        if save_optimizer:\n",
    "            save_dict['optimizer'] = self.optimizer.state_dict()\n",
    "\n",
    "        if save_path is None:\n",
    "            timestr = time.strftime('%m%d%H%M')\n",
    "            save_path = 'checkpoints/fasterrcnn_%s' % timestr\n",
    "            for k_, v_ in kwargs.items():\n",
    "                save_path += '_%s' % v_\n",
    "\n",
    "        save_dir = os.path.dirname(save_path)\n",
    "        if not os.path.exists(save_dir):\n",
    "            os.makedirs(save_dir)\n",
    "\n",
    "        t.save(save_dict, save_path)\n",
    "        self.vis.save([self.vis.env])\n",
    "        return save_path\n",
    "\n",
    "    def load(self, path, load_optimizer=True, parse_opt=False, ):\n",
    "        state_dict = t.load(path)\n",
    "        if 'model' in state_dict:\n",
    "            self.faster_rcnn.load_state_dict(state_dict['model'])\n",
    "        else:  # legacy way, for backward compatibility\n",
    "            self.faster_rcnn.load_state_dict(state_dict)\n",
    "            return self\n",
    "        if parse_opt:\n",
    "            opt._parse(state_dict['config'])\n",
    "        if 'optimizer' in state_dict and load_optimizer:\n",
    "            self.optimizer.load_state_dict(state_dict['optimizer'])\n",
    "        return self\n",
    "\n",
    "    def update_meters(self, losses):\n",
    "        loss_d = {k: at.scalar(v) for k, v in losses._asdict().items()}\n",
    "        for key, meter in self.meters.items():\n",
    "            meter.add(loss_d[key])\n",
    "\n",
    "    def reset_meters(self):\n",
    "        for key, meter in self.meters.items():\n",
    "            meter.reset()\n",
    "        self.roi_cm.reset()\n",
    "        self.rpn_cm.reset()\n",
    "\n",
    "    def get_meter_data(self):\n",
    "        return {k: v.value()[0] for k, v in self.meters.items()}\n",
    "\n",
    "\n",
    "def _smooth_l1_loss(x, t, in_weight, sigma):\n",
    "    sigma2 = sigma ** 2\n",
    "    diff = in_weight * (x - t)\n",
    "    abs_diff = diff.abs()\n",
    "    flag = (abs_diff.data < (1. / sigma2)).float()\n",
    "    y = (flag * (sigma2 / 2.) * (diff ** 2) +\n",
    "         (1 - flag) * (abs_diff - 0.5 / sigma2))\n",
    "    return y.sum()\n",
    "\n",
    "\n",
    "def _fast_rcnn_loc_loss(pred_loc, gt_loc, gt_label, sigma):\n",
    "    in_weight = t.zeros(gt_loc.shape).cuda()\n",
    "    # Localization loss is calculated only for positive rois.\n",
    "    # NOTE:  unlike origin implementation, \n",
    "    # we don't need inside_weight and outside_weight, they can calculate by gt_label\n",
    "    in_weight[(gt_label > 0).view(-1, 1).expand_as(in_weight).cuda()] = 1\n",
    "    loc_loss = _smooth_l1_loss(pred_loc, gt_loc, in_weight.detach(), sigma)\n",
    "    # Normalize by total number of negtive and positive rois.\n",
    "    loc_loss /= ((gt_label >= 0).sum().float()) # ignore gt_label==-1 for rpn_loss\n",
    "    return loc_loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
